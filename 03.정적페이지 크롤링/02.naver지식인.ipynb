{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#첫번째 질문의 제목, 링크, 날짜, 내용\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 응답 객체 받아오기\n",
    "response = requests.get('https://kin.naver.com/search/list.naver?query=%EB%B9%BC%EB%B9%BC%EB%A1%9C%EB%8D%B0%EC%9D%B4')\n",
    "#html 코드 받아오기\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "anchor = soup.select_one('._searchListTitleAnchor')\n",
    "dd = soup.select_one('.txt_inline')\n",
    "dd_2 = soup.select_one('dl > dd:nth-of-type(2)')\n",
    "title  = anchor.text\n",
    "link = anchor.attrs['href']\n",
    "date = dd.text\n",
    "text = dd_2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#열개 질문의 제목, 링크,날짜,내용\n",
    "anchor = soup.select('._searchListTitleAnchor')\n",
    "dd = soup.select('.txt_inline')\n",
    "dd_2 = soup.select('dl > dd:nth-of-type(2)')\n",
    "title = []\n",
    "link = []\n",
    "date = []\n",
    "con = []\n",
    "for i in anchor:\n",
    "    title.append(i.text)\n",
    "    link.append(i.attrs['href'])\n",
    "for i in dd:\n",
    "    date.append(i.text)\n",
    "for i in dd_2:\n",
    "    con.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#열개 질문의 제목, 링크,날짜,내용\n",
    "li = soup.select('.basic1 > li')\n",
    "a = 0\n",
    "for i in li:    \n",
    "    anchor = i.select_one('._searchListTitleAnchor')\n",
    "    title = anchor.text\n",
    "    url = anchor.attrs['href']\n",
    "    date = i.select_one('dt+dd').text\n",
    "    con = i.select_one('dt+dd+dd').text\n",
    "    s = '\\n'\n",
    "    a+=1\n",
    "    print (f'{a} : {title}{s}{url}\\n{date}\\n{con}',end='\\n'*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n개 페이지에서 열개 질문의 제목, 링크, 날짜, 내용\n",
    "n = int(input('크롤링할페이지수 입력'))\n",
    "a = 0\n",
    "for i in range(1,n+1):\n",
    "    print(f'{i}페이지 크롤링중')\n",
    "    response = requests.get(f'https://kin.naver.com/search/list.naver?query=%EB%B9%BC%EB%B9%BC%EB%A1%9C%EB%8D%B0%EC%9D%B4&page={i}')\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    li = soup.select('.basic1 > li')\n",
    "    \n",
    "    for j in li:    \n",
    "        anchor = j.select_one('._searchListTitleAnchor')\n",
    "        title = anchor.text\n",
    "        url = anchor.attrs['href']\n",
    "        date = j.select_one('dt+dd').text\n",
    "        con = j.select_one('dt+dd+dd').text\n",
    "        s = '\\n'\n",
    "        a+=1\n",
    "        print (f'{a} : {title}{s}{url}\\n{date}\\n{con}',end='\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정키워드 n개 페이지에서 열개 질문의 제목, 링크, 날짜, 내용\n",
    "key= input('키워드를 입력하세요')\n",
    "n = int(input('크롤링할페이지수 입력'))\n",
    "a = 0\n",
    "for i in range(1,n+1):\n",
    "    print(f'{i}페이지 크롤링중')\n",
    "    response = requests.get(f'https://kin.naver.com/search/list.naver?query={key}&page={i}')\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    li = soup.select('.basic1 > li')\n",
    "    \n",
    "    for j in li:    \n",
    "        anchor = j.select_one('._searchListTitleAnchor')\n",
    "        title = anchor.text\n",
    "        url = anchor.attrs['href']\n",
    "        date = j.select_one('dt+dd').text\n",
    "        con = j.select_one('dt+dd+dd').text\n",
    "        s = '\\n'\n",
    "        a+=1\n",
    "        print (f'{a} : {title}{s}{url}\\n{date}\\n{con}',end='\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정키워드로 n개 페이지에서 열개 질문의 제목, 링크, 날짜, 내용 저장하기\n",
    "import openpyxl\n",
    "key= input('키워드를 입력하세요')\n",
    "n = int(input('크롤링할페이지수 입력'))\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active #활성화된 시트 선택\n",
    "ws.title = key #시트이름 변경\n",
    "\n",
    "ws.append(['순번','제목','링크','날짜','내용'])\n",
    "\n",
    "a = 0\n",
    "for i in range(1,n+1):\n",
    "    print(f'{i}페이지 크롤링중')\n",
    "    response = requests.get(f'https://kin.naver.com/search/list.naver?query={key}&page={i}')\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    li = soup.select('.basic1 > li')\n",
    "    \n",
    "    for j in li:    \n",
    "        anchor = j.select_one('._searchListTitleAnchor')\n",
    "        title = anchor.text\n",
    "        url = anchor.attrs['href']\n",
    "        date = j.select_one('dt+dd').text\n",
    "        con = j.select_one('dt+dd+dd').text\n",
    "        s = '\\n'\n",
    "        a+=1\n",
    "        print (f'{a} : {title}{s}{url}\\n{date}\\n{con}',end='\\n'*3)\n",
    "        ws.append([a,title,url,date,con])\n",
    "\n",
    "wb.save(f'{key}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
